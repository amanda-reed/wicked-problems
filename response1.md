## Data Science Reflection

### Fairness in AI Systems

Today, technology is used in almost every aspect of our daily lives. Our work, school, and social lives are powered by thousands of algorithms that aim to make our lives easier.
In particular, machine learning and artificial intelligence systems use data, including observations and interactions in the real-world, to predict or act like human behavior.
On a daily basis, we encounter AI systems in social media, smart personal assistants, online shopping, typing suggestions, and more. As intelligent, and at times shockingly
accurate, as these systems may be, there are often flaws in the fairness of performance and results.

Because technology is designed by humans with bias or prejudice, the result also has some level of bias or unfairness in its design. This can cause **allocation harms** or 
**quality-of-service harms**. Allocation harms affect the extent to which users are given access to information or resources while quality-of-service harms affect the quality of 
service for a given user. Even if the creator keeps fairmindedness in mind, their commitment to their own definition of fairness can have consequences. What may be impartial 
in function may be discriminatory in practice. This is often referred to as **disparate-impact**. While some AI systems may have built in algorithms to deter from specific biases,
it is this attention to certain groups that may still cause harm to users. 

Fairlearn is a Python package that can determine the fairness of an AI system. A dashboard is used to evaluate which groups are affected by unfairness and a series of 
algorithms moderate unfairness. By using Fairlearn, businesses can assess the reputability of their systems in regard to how fair they perform given a series of tasks
and users.  After indicating a specific identifying feature of a potential user, such as race or gender, Fairlearn maps the accuracy of the AI performance.  Despite the
struggles many AI system designers face in creating technology without bias or subjectivity, tools such as Fairlearn can pave the way to more balanced AI systems for the future.


#### References

Lazzeri, F., PhD. (2020, June 02). How to Assess AI System's Fairness and Mitigate Any Observed Unfairness Issues. Retrieved September 09,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2020, from https://medium.com/@ODSC/how-to-assess-ai-systems-fairness-and-mitigate-any-observed-unfairness-issues-cb2b56cffd11

Wong, L. (2017, October 16). Experts Weigh in on Fairness and Performance Trade-Offs in Machine Learning. Retrieved September 09, 2020, 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from https://www.theregreview.org/2017/10/04/wong-fairness-performance-machine-learning/
